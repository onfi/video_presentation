# 仕様書

## 概要
Text to SpeechとMarpを使い、日本語でプレゼンテーション動画を自動生成するアプリケーション。

## 技術スタック

- Python
- Gemini APIを使用し、Marp用のMarkdown、ナレーション用のテキストを生成する。
- Hugging FaceのText to Speechモデルをダウンロードして使用する。
  - 適切なモデルを切り替えられるようにする。
- pyrubberbandを使用し、高品質な音声の速度調整を行う。
  - `rubberband-cli`へのシステム依存がある。
- Marp CLIを使用して、Markdownからスライドを生成する。
- 音声とスライドを結合し、動画を生成する。

## 機能要件

複数のバッチからなり、各バッチは以下のステップを含む。

### 1. スライド用Markdown作成
- Gemini APIを使用し、プレゼンテーションの内容に基づいてスライド用Markdownを生成する。
- プレゼンテーションの内容が記載されたファイルのパスを、引数として受け取る。
- オプション:
    - `-n` または `--num-slides`: スライドの枚数を指定する。省略した場合はGeminiに任せる。
    - `-t` または `--time`: 最終的な動画の想定時間を秒で指定する。省略した場合は180秒。
    - `-p` または `--project`: プロジェクト名を指定する。省略した場合、プレゼンテーションの内容のファイル名から拡張子を除いたものを使用する。
- 出力: `./outputs/{project_name}/slides.md`

### 2. ナレーション用テキスト作成
- 引数としてプロジェクト名を受け取る。
- `./outputs/{project_name}/slides.md`を読み込み、各スライドに対応するナレーション用テキストをGeminiで生成する。
- 出力: `./outputs/{project_name}/narration/{index}.txt`
    - `index`はスライドの番号、3桁ゼロパディング。

### 3. スライド画像生成
- 引数としてプロジェクト名を受け取る。
- Marp CLIを使用し、`./outputs/{project_name}/slides.md`からスライド画像を生成する。
- オプション:
    - `--theme`: Marpのテーマを指定する。省略した場合はデフォルトテーマを使用する。
- 出力: `./outputs/{project_name}/slides/{index}.png`
    - `index`はスライドの番号、3桁ゼロパディング。
    - 1920x1080のPNG画像。

### 4. ナレーション音声生成
- 引数としてプロジェクト名を受け取る。
- style-bert-vits2を使用し、`./outputs/{project_name}/narration{index}.txt`からナレーション音声を生成する。
- 最終的な動画の想定時間から、各スライドのナレーション音声の長さをナレーションのテキストの長さに応じて均等に割り振る。
- オプション:
    - `--model`: 使用するText to Speechモデルを指定する。省略した場合は`auto`エンジンを使用する。
    - `-t` または `--time`: 最終的な動画の想定時間を秒で指定する。省略した場合は180秒。
- 出力: `./outputs/{project_name}/audio/slide{index}.mp3`

### 5. スライドごとの動画生成
- 引数としてプロジェクト名を受け取る。
- 各スライド画像と対応するナレーション音声を結合し、スライドごとの動画を生成する。
- 出力: `./outputs/{project_name}/video/slide{index}.mp4`
    - `index`はスライドの番号、3桁ゼロパディング。
    - 動画の長さは音声ファイルに合わせる。

### 6. 最終動画生成
- 引数としてプロジェクト名を受け取る。
- スライドごとの動画を結合し、最終的なプレゼンテーション動画を生成する。
- 出力: `./outputs/{project_name}/presentation.mp4`

## 実行フロー
各バッチは独立して実行可能。
まとめて全てのバッチを実行するスクリプトも用意する。